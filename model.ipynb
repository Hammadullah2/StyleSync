{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4195e537",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# # Building a Recommendation System Using CNN \n",
    "# This notebook builds a CNN-based Fashion Embedding model and integrates full MLOps monitoring:\n",
    "# - MLflow for experiment tracking  \n",
    "# - Prometheus & Grafana for system metrics  \n",
    "# - Evidently AI for data drift reporting\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Step 1: Install Dependencies\n",
    "!pip install tensorflow==2.12 keras mlflow evidently prometheus_client psutil matplotlib seaborn scikit-learn pandas numpy opencv-python --quiet\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Step 2: Imports and Monitoring Setup\n",
    "import os\n",
    "import time\n",
    "import threading\n",
    "import psutil\n",
    "import mlflow\n",
    "import mlflow.keras\n",
    "from prometheus_client import Gauge, start_http_server\n",
    "from evidently.report import Report\n",
    "from evidently.metric_preset import DataDriftPreset\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import cv2\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "from sklearn.manifold import TSNE\n",
    "from keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Sequential\n",
    "from keras.layers import GlobalMaxPooling2D\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Step 3: MLflow Configuration\n",
    "# MLFLOW_TRACKING_URI = \"http://<YOUR-EC2-IP>:5000\"  # <-- Replace with your EC2 public IP\n",
    "MLFLOW_TRACKING_URI = \"http://127.0.0.1:5000\"  # <-- local\n",
    "\n",
    "mlflow.set_tracking_uri(MLFLOW_TRACKING_URI)\n",
    "mlflow.set_experiment(\"CNN_Fashion_Recommender\")\n",
    "mlflow.start_run(run_name=\"CNN_Embedding_Model\")\n",
    "\n",
    "mlflow.log_param(\"base_model\", \"ResNet50\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Step 4: Prometheus System Metrics Setup\n",
    "# Start Prometheus metrics exporter on port 8000\n",
    "start_http_server(8000)\n",
    "\n",
    "cpu_usage = Gauge('cpu_usage_percent', 'CPU usage percentage')\n",
    "ram_usage = Gauge('ram_usage_percent', 'RAM usage percentage')\n",
    "\n",
    "print(\"âœ… Prometheus metrics available at :8000\")\n",
    "\n",
    "def monitor_system():\n",
    "    while True:\n",
    "        cpu_usage.set(psutil.cpu_percent())\n",
    "        ram_usage.set(psutil.virtual_memory().percent)\n",
    "        time.sleep(5)\n",
    "\n",
    "threading.Thread(target=monitor_system, daemon=True).start()\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Step 5: Data Preparation\n",
    "DATASET_PATH = \"/kaggle/input/fashion-product-images-dataset/fashion-dataset/fashion-dataset/\"\n",
    "print(os.listdir(DATASET_PATH))\n",
    "\n",
    "df = pd.read_csv(DATASET_PATH + \"styles.csv\", nrows=5000, on_bad_lines='skip')\n",
    "df['image'] = df.apply(lambda row: str(row['id']) + \".jpg\", axis=1)\n",
    "df = df.reset_index(drop=True)\n",
    "mlflow.log_param(\"dataset_size\", len(df))\n",
    "df.head()\n",
    "\n",
    "# %% [markdown]\n",
    "# ### Image Utilities\n",
    "def img_path(img):\n",
    "    return DATASET_PATH+\"/images/\"+img\n",
    "\n",
    "def load_image(img, resized_fac=0.1):\n",
    "    img = cv2.imread(img_path(img))\n",
    "    if img is None:\n",
    "        return np.zeros((224,224,3), dtype=np.uint8)\n",
    "    w, h, _ = img.shape\n",
    "    resized = cv2.resize(img, (int(h*resized_fac), int(w*resized_fac)), interpolation=cv2.INTER_AREA)\n",
    "    return resized\n",
    "\n",
    "def plot_figures(figures, nrows=1, ncols=1, figsize=(8,8)):\n",
    "    fig, axeslist = plt.subplots(ncols=ncols, nrows=nrows, figsize=figsize)\n",
    "    for ind,title in enumerate(figures):\n",
    "        axeslist.ravel()[ind].imshow(cv2.cvtColor(figures[title], cv2.COLOR_BGR2RGB))\n",
    "        axeslist.ravel()[ind].set_title(title)\n",
    "        axeslist.ravel()[ind].set_axis_off()\n",
    "    plt.tight_layout()\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Step 6: Model Creation\n",
    "img_width, img_height = 224, 224\n",
    "\n",
    "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(img_width, img_height, 3))\n",
    "base_model.trainable = False\n",
    "\n",
    "model = Sequential([\n",
    "    base_model,\n",
    "    GlobalMaxPooling2D()\n",
    "])\n",
    "\n",
    "model.summary()\n",
    "mlflow.log_param(\"trainable_layers\", 0)\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Step 7: Embedding Extraction\n",
    "def get_embedding(model, img_name):\n",
    "    img = image.load_img(img_path(img_name), target_size=(img_width, img_height))\n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = preprocess_input(x)\n",
    "    return model.predict(x).reshape(-1)\n",
    "\n",
    "sample_img = df.iloc[0].image\n",
    "emb = get_embedding(model, sample_img)\n",
    "mlflow.log_param(\"embedding_dim\", len(emb))\n",
    "print(\"Embedding shape:\", emb.shape)\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Step 8: Compute Embeddings for Dataset\n",
    "df_sample = df.sample(1000, random_state=42)  # limit for speed\n",
    "df_embs = df_sample['image'].apply(lambda img: get_embedding(model, img))\n",
    "df_embs = df_embs.apply(pd.Series)\n",
    "\n",
    "mlflow.log_metric(\"processed_images\", len(df_embs))\n",
    "df_embs.to_csv(\"embeddings.csv\", index=False)\n",
    "mlflow.log_artifact(\"embeddings.csv\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Step 9: Compute Similarity Matrix\n",
    "cosine_sim = 1 - pairwise_distances(df_embs, metric='cosine')\n",
    "print(\"Cosine similarity computed.\")\n",
    "mlflow.log_metric(\"mean_cosine_similarity\", float(np.mean(cosine_sim)))\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Step 10: Data Drift Detection with Evidently AI\n",
    "df_ref = df_sample.sample(frac=0.7, random_state=42)\n",
    "df_test = df_sample.drop(df_ref.index)\n",
    "\n",
    "report = Report(metrics=[DataDriftPreset()])\n",
    "report.run(reference_data=df_ref, current_data=df_test)\n",
    "report.save_html(\"evidently_drift_report.html\")\n",
    "\n",
    "mlflow.log_artifact(\"evidently_drift_report.html\")\n",
    "\n",
    "# Serve locally (if on EC2)\n",
    "!python3 -m http.server 7000 --directory .\n",
    "\n",
    "# print(\"âœ… Evidently Dashboard: http://<YOUR-EC2-IP>:7000/evidently_drift_report.html\")\n",
    "print(\"âœ… Evidently Dashboard: http://127.0.0.1:7000/evidently_drift_report.html\")\n",
    "\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Step 11: Visualization of Embeddings\n",
    "tsne = TSNE(n_components=2, verbose=0, perplexity=40, n_iter=300)\n",
    "tsne_results = tsne.fit_transform(df_embs)\n",
    "df_sample['tsne-2d-one'] = tsne_results[:,0]\n",
    "df_sample['tsne-2d-two'] = tsne_results[:,1]\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "sns.scatterplot(x=\"tsne-2d-one\", y=\"tsne-2d-two\", hue=\"masterCategory\", data=df_sample, legend=\"full\", alpha=0.8)\n",
    "plt.savefig(\"tsne_clusters.png\")\n",
    "mlflow.log_artifact(\"tsne_clusters.png\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Step 12: Wrap Up\n",
    "mlflow.log_metric(\"total_categories\", df['masterCategory'].nunique())\n",
    "mlflow.end_run()\n",
    "\n",
    "# print(\"âœ… MLflow Tracking URL:\", MLFLOW_TRACKING_URI)\n",
    "# print(\"âœ… Prometheus running on port 8000\")\n",
    "# print(\"âœ… Grafana: http://<YOUR-EC2-IP>:3000\")\n",
    "# print(\"âœ… Evidently Dashboard: http://<YOUR-EC2-IP>:7000/evidently_drift_report.html\")\n",
    "print(\"âœ… MLflow Tracking URL: http://127.0.0.1:5000\")\n",
    "print(\"âœ… Prometheus running on port 8000\")\n",
    "print(\"âœ… Grafana: http://127.0.0.1:3000\")\n",
    "print(\"âœ… Evidently Dashboard: http://127.0.0.1:7000/evidently_drift_report.html\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a77184",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# # ðŸ§¥ Building a CNN-Based Fashion Recommendation System (Local MLOps)\n",
    "# This notebook builds a CNN-based Fashion Embedding model with:\n",
    "# - MLflow for experiment tracking (localhost:5000)\n",
    "# - Prometheus & Grafana for live system metrics\n",
    "# - Evidently AI for drift monitoring (localhost:7000)\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Step 1: Install Dependencies\n",
    "!pip install  keras mlflow evidently prometheus_client psutil matplotlib seaborn scikit-learn pandas numpy opencv-python --quiet\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Step 2: Imports and Monitoring Setup\n",
    "import os\n",
    "import time\n",
    "import threading\n",
    "import psutil\n",
    "import mlflow\n",
    "import mlflow.keras\n",
    "from prometheus_client import Gauge, start_http_server\n",
    "from evidently.report import Report\n",
    "from evidently.metric_preset import DataDriftPreset\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import cv2\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "from sklearn.manifold import TSNE\n",
    "from keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Sequential\n",
    "from keras.layers import GlobalMaxPooling2D\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Step 3: MLflow Configuration (Localhost)\n",
    "MLFLOW_TRACKING_URI = \"http://127.0.0.1:5000\"  # Local MLflow\n",
    "\n",
    "mlflow.set_tracking_uri(MLFLOW_TRACKING_URI)\n",
    "mlflow.set_experiment(\"CNN_Fashion_Recommender\")\n",
    "mlflow.start_run(run_name=\"CNN_Embedding_Model\")\n",
    "\n",
    "mlflow.log_param(\"base_model\", \"ResNet50\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Step 4: Prometheus System Metrics Setup (localhost:8000)\n",
    "start_http_server(8000)\n",
    "\n",
    "cpu_usage = Gauge('cpu_usage_percent', 'CPU usage percentage')\n",
    "ram_usage = Gauge('ram_usage_percent', 'RAM usage percentage')\n",
    "\n",
    "print(\"âœ… Prometheus metrics available at :8000\")\n",
    "\n",
    "def monitor_system():\n",
    "    while True:\n",
    "        cpu_usage.set(psutil.cpu_percent())\n",
    "        ram_usage.set(psutil.virtual_memory().percent)\n",
    "        time.sleep(5)\n",
    "\n",
    "threading.Thread(target=monitor_system, daemon=True).start()\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Step 5: Data Preparation\n",
    "DATASET_PATH = \"path_to_your_local_dataset/fashion-dataset/\"  # e.g., C:/Users/USER/Downloads/fashion-dataset/\n",
    "df = pd.read_csv(DATASET_PATH + \"styles.csv\", nrows=5000, on_bad_lines='skip')\n",
    "df['image'] = df.apply(lambda row: str(row['id']) + \".jpg\", axis=1)\n",
    "df = df.reset_index(drop=True)\n",
    "mlflow.log_param(\"dataset_size\", len(df))\n",
    "df.head()\n",
    "\n",
    "def img_path(img):\n",
    "    return os.path.join(DATASET_PATH, \"images\", img)\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Step 6: Model Creation\n",
    "img_width, img_height = 224, 224\n",
    "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(img_width, img_height, 3))\n",
    "base_model.trainable = False\n",
    "\n",
    "model = Sequential([\n",
    "    base_model,\n",
    "    GlobalMaxPooling2D()\n",
    "])\n",
    "\n",
    "mlflow.log_param(\"trainable_layers\", 0)\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Step 7: Embedding Extraction\n",
    "def get_embedding(model, img_name):\n",
    "    img = image.load_img(img_path(img_name), target_size=(img_width, img_height))\n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = preprocess_input(x)\n",
    "    return model.predict(x).reshape(-1)\n",
    "\n",
    "sample_img = df.iloc[0].image\n",
    "emb = get_embedding(model, sample_img)\n",
    "mlflow.log_param(\"embedding_dim\", len(emb))\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Step 8: Compute Embeddings and Similarity\n",
    "df_sample = df.sample(1000, random_state=42)\n",
    "df_embs = df_sample['image'].apply(lambda img: get_embedding(model, img))\n",
    "df_embs = df_embs.apply(pd.Series)\n",
    "mlflow.log_metric(\"processed_images\", len(df_embs))\n",
    "\n",
    "cosine_sim = 1 - pairwise_distances(df_embs, metric='cosine')\n",
    "mlflow.log_metric(\"mean_cosine_similarity\", float(np.mean(cosine_sim)))\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Step 9: Evidently Data Drift Dashboard (localhost:7000)\n",
    "df_ref = df_sample.sample(frac=0.7, random_state=42)\n",
    "df_test = df_sample.drop(df_ref.index)\n",
    "\n",
    "report = Report(metrics=[DataDriftPreset()])\n",
    "report.run(reference_data=df_ref, current_data=df_test)\n",
    "report.save_html(\"evidently_drift_report.html\")\n",
    "mlflow.log_artifact(\"evidently_drift_report.html\")\n",
    "\n",
    "# Serve the report locally\n",
    "!python3 -m http.server 7000 --directory .\n",
    "\n",
    "print(\"âœ… Evidently Dashboard: http://127.0.0.1:7000/evidently_drift_report.html\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Step 10: Wrap Up\n",
    "mlflow.log_metric(\"total_categories\", df['masterCategory'].nunique())\n",
    "mlflow.end_run()\n",
    "\n",
    "print(\"âœ… MLflow Tracking URL: http://127.0.0.1:5000\")\n",
    "print(\"âœ… Prometheus running on port 8000\")\n",
    "print(\"âœ… Grafana: http://127.0.0.1:3000\")\n",
    "print(\"âœ… Evidently Dashboard: http://127.0.0.1:7000/evidently_drift_report.html\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
